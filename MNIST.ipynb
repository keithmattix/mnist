{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras import models, layers\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing this code does is initialize our model. For this task, we chose a ***sequential*** model, one of the most simple neural network organizations. In this model, each layer is processed right after the previous one. In this particular example, both of our hidden layers are ***fully-connected*** or ***Dense***, meaning that each node in each layer sends its information to every node in the next layer. In other words, every pair of layers is a bipartite graph. The first hidden layer has 512 nodes and uses the ***Re***_ctified_ ***L***_inear_ ***u***_nit_ activation function. An ***activation*** function is a mathematical function that defines the output of each node in the layer, and ReLU is one of the simplest. According to the keras website, ReLU is defined as follows:\n",
    "\n",
    "> `relu(x, alpha=0.0, max_value=None)`<br />\n",
    "> x if x > 0, alpha * x if x < 0. If max_value is defined, the result is truncated to this value.\n",
    "\n",
    "\n",
    "So essentially, each positive value maps to itself and negative values map to 0. The second layer is a 10 node ***softmax*** layer which will return an array of 10 probability scores (summing to 1). Each score will be the probability that the original input digit belongs to one of the 10 digit classes (0-9).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
